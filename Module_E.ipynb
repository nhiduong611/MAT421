{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOq+I/F5Xf4rw/o21C+Wmie",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhiduong611/MAT421/blob/main/Module_E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taylor theorem"
      ],
      "metadata": {
        "id": "aVGP7jUqy5pj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-HD_cBLum3E",
        "outputId": "4361a699-69c0-466a-ccc4-256fc907070c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact value of e^1: 2.718281828459045\n",
            "Taylor series approximation with 10 terms: 2.7182815255731922\n"
          ]
        }
      ],
      "source": [
        "# Use Taylor theorem to estimate e^x at x = 0\n",
        "\n",
        "import math\n",
        "\n",
        "def taylor_series_e_to_x(x, n):\n",
        "    \"\"\"Approximate e^x using Taylor series with n terms.\"\"\"\n",
        "    approximation = 0\n",
        "    for i in range(n):\n",
        "        approximation += x**i / math.factorial(i)\n",
        "    return approximation\n",
        "\n",
        "# Example usage\n",
        "x = 1  # Point at which to approximate e^x\n",
        "n = 10  # Number of terms in the Taylor series\n",
        "\n",
        "exact_value = math.exp(x)\n",
        "approximation = taylor_series_e_to_x(x, n)\n",
        "\n",
        "print(f\"Exact value of e^{x}: {exact_value}\")\n",
        "print(f\"Taylor series approximation with {n} terms: {approximation}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continuity and Differentiation"
      ],
      "metadata": {
        "id": "JRHZKESczUhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the function f(x)=x^2+3x+5 if it continues at x=1 and find its derivatives\n",
        "from sympy import symbols, Function, diff, limit, S\n",
        "\n",
        "# Define the symbol and function\n",
        "x = symbols('x')\n",
        "f = x**2 + 3*x + 5\n",
        "\n",
        "# Check continuity at x = 1\n",
        "f_at_1 = f.subs(x, 1)  # f(1)\n",
        "limit_f_at_1 = limit(f, x, 1)  # Limit of f as x approaches 1\n",
        "\n",
        "# Differentiate f with respect to x\n",
        "f_prime = diff(f, x)\n",
        "\n",
        "# Output the results\n",
        "f_at_1, limit_f_at_1, f_prime\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBjVfZmZz4WT",
        "outputId": "3479330a-5d29-40d1-9696-0bc92d727c31"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 9, 2*x + 3)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization with gradient descent\n",
        "\n"
      ],
      "metadata": {
        "id": "JKpBzUZW0mV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We try to minimize the function f(x)=x^2+10x+25\n",
        "def f(x):\n",
        "    \"\"\"The function to minimize.\"\"\"\n",
        "    return x**2 + 10*x + 25\n",
        "\n",
        "def grad_f(x):\n",
        "    \"\"\"Gradient (derivative) of the function.\"\"\"\n",
        "    return 2*x + 10\n",
        "\n",
        "def gradient_descent(starting_point, learning_rate, n_iterations):\n",
        "    \"\"\"Performs gradient descent optimization.\"\"\"\n",
        "    x = starting_point\n",
        "    for _ in range(n_iterations):\n",
        "        grad = grad_f(x)  # Compute the gradient at the current point\n",
        "        x = x - learning_rate * grad  # Update x by taking a step in the opposite direction of the gradient\n",
        "    return x\n",
        "\n",
        "# Parameters\n",
        "starting_point = 0  # Initial guess\n",
        "learning_rate = 0.1  # Step size\n",
        "n_iterations = 100  # Number of iterations\n",
        "\n",
        "# Perform gradient descent\n",
        "minimum_x = gradient_descent(starting_point, learning_rate, n_iterations)\n",
        "\n",
        "# Results\n",
        "minimum_x, f(minimum_x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywcoOiNh0pip",
        "outputId": "c94581ca-271e-407d-888f-c0d878e29538"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-4.999999998981481, 3.552713678800501e-15)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}